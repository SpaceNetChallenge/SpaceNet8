{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dda134",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "converts ground truth geojson files (both buildings and roads) to a csv of format: \n",
    "The geojsons should be prepped (includes \"inferred_speed_mps\" as property) and cleaned using the data_prep functions.\n",
    "\n",
    "'ImageId', 'Object','Wkt_Pix','Flooded', 'length_m', 'travel_time_s'  \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import shapely.wkt\n",
    "from shapely.geometry import shape, Polygon, LineString, MultiLineString\n",
    "from osgeo import gdal, osr, ogr\n",
    "\n",
    "def make_wgs84_utm_srs(longitude, latitude):\n",
    "    \"\"\" create a Spatial Reference object that is a WGS84 UTM projected coord system\n",
    "    from longitude and latitude values.\"\"\"\n",
    "    north = int(latitude > 0)\n",
    "    approx_zone = int((longitude + 180) / 6)\n",
    "    srs = osr.SpatialReference()\n",
    "    srs.SetUTM(approx_zone, north) # zone, north=1,\n",
    "    srs.SetWellKnownGeogCS(\"WGS84\")\n",
    "    return srs\n",
    "\n",
    "def lat_lon_to_row_col(xs, ys, geotran):\n",
    "    cols = []\n",
    "    rows = []\n",
    "    for i in range(len(xs)):\n",
    "        point = ogr.Geometry(ogr.wkbPoint)\n",
    "        point.AddPoint(xs[i], ys[i])\n",
    "        newx, newy = point.GetX(), point.GetY()\n",
    "        col = (newx - geotran[0]) / geotran[1]\n",
    "        row = (newy - geotran[3]) / geotran[5]\n",
    "        cols.append(col)\n",
    "        rows.append(row)\n",
    "    return cols, rows\n",
    "    \n",
    "def length_of_segments(full_linestring_wkt, x_node, y_node):\n",
    "    source = osr.SpatialReference() # the input dataset is in wgs84\n",
    "    source.ImportFromEPSG(4326)\n",
    "    source.SetAxisMappingStrategy(osr.OAMS_TRADITIONAL_GIS_ORDER) # this is required for gdal>=3.0. The axis ordering is different between 3.x (y, x) and 2.x (x, y). see: https://github.com/OSGeo/gdal/issues/1546\n",
    "    target_srs = make_wgs84_utm_srs(x_node, y_node)\n",
    "    transform_to_utm = osr.CoordinateTransformation(source, target_srs) # transform from wgs84 gcs to utm\n",
    "    \n",
    "    ogr_linestring = ogr.CreateGeometryFromWkt(full_linestring_wkt)\n",
    "    ogr_linestring.Transform(transform_to_utm)\n",
    "    \n",
    "    shapely_linestring = shapely.wkt.loads(ogr_linestring.ExportToWkt())\n",
    "    \n",
    "    segments = [LineString([shapely_linestring.coords[i], shapely_linestring.coords[i+1]]) for i in range(len(shapely_linestring.coords) - 1)]\n",
    "    lengths_m = []\n",
    "    for s in segments:\n",
    "        lengths_m.append(s.length)\n",
    "    transform_to_utm = None\n",
    "    return lengths_m\n",
    "\n",
    "def get_records(geojson, image):\n",
    "    \"\"\"\n",
    "    for roads\n",
    "    \"\"\"\n",
    "    f = open(geojson)\n",
    "    data = json.load(f)\n",
    "    f.close()\n",
    "    \n",
    "    image_id = os.path.basename(image).split(\".\")[0]\n",
    "    \n",
    "    imds = gdal.Open(image) # in espg 4326\n",
    "    geotran = imds.GetGeoTransform()\n",
    "    imds = None\n",
    "    \n",
    "    out_records = [] # id, Road, \n",
    "    for feature in data[\"features\"]:\n",
    "        geometry = shape(feature[\"geometry\"]) # in epsg 4326\n",
    "        if geometry.geom_type == \"MultiLineString\":\n",
    "            for line_geom in geometry:\n",
    "                x, y = line_geom.coords.xy\n",
    "\n",
    "                cols, rows = lat_lon_to_row_col(x, y, geotran)\n",
    "                segment_lengths_m = length_of_segments(line_geom.wkt, x[0], y[0])\n",
    "\n",
    "                flood_attr = True\n",
    "                if feature[\"properties\"][\"flooded\"] is None:\n",
    "                    flood_attr = False\n",
    "\n",
    "                for i in range(len(cols)-1):\n",
    "                    wktsegment = LineString([(cols[i], rows[i]), (cols[i+1], rows[i+1])]).wkt\n",
    "                    out_records.append([image_id, \"Road\", wktsegment, flood_attr,\n",
    "                                        segment_lengths_m[i],\n",
    "                                        segment_lengths_m[i] / feature[\"properties\"][\"inferred_speed_mps\"]])\n",
    "        else:\n",
    "            x, y = geometry.coords.xy\n",
    "\n",
    "            cols, rows = lat_lon_to_row_col(x, y, geotran)\n",
    "            segment_lengths_m = length_of_segments(geometry.wkt, x[0], y[0])\n",
    "\n",
    "            flood_attr = True\n",
    "            if feature[\"properties\"][\"flooded\"] is None:\n",
    "                flood_attr = False\n",
    "\n",
    "            for i in range(len(cols)-1):\n",
    "                wktsegment = LineString([(cols[i], rows[i]), (cols[i+1], rows[i+1])]).wkt\n",
    "                out_records.append([image_id, \"Road\", wktsegment, flood_attr,\n",
    "                                    segment_lengths_m[i],\n",
    "                                    segment_lengths_m[i] / feature[\"properties\"][\"inferred_speed_mps\"]])\n",
    "    return out_records\n",
    "    \n",
    "def match_im_label(annotations, pre_images, post_images):\n",
    "    out_pre = []\n",
    "    out_anno = []\n",
    "    out_post = []\n",
    "    for i in annotations:\n",
    "        tileid = os.path.basename(i).split(\".\")[0]\n",
    "        pre_im = [j for j in pre_images if f\"_{tileid}.tif\" in j][0]\n",
    "        post_im = [j for j in post_images if f\"_{tileid}.tif\" in j][0]\n",
    "        \n",
    "        out_anno.append(i)\n",
    "        out_pre.append(pre_im)\n",
    "        out_post.append(post_im)\n",
    "    return out_anno, out_pre, out_post\n",
    "    \n",
    "def match_im_label_road(annotations, pre_images, post_images):\n",
    "    out_pre = []\n",
    "    out_anno = []\n",
    "    out_post = []\n",
    "    for i in annotations:\n",
    "        tileid = os.path.basename(i).split(\"roads_speed_\")[-1].split(\".\")[0]\n",
    "        pre_im = [j for j in pre_images if f\"_{tileid}.tif\" in j][0]\n",
    "        post_im = [j for j in post_images if f\"_{tileid}.tif\" in j][0]\n",
    "        \n",
    "        out_anno.append(i)\n",
    "        out_pre.append(pre_im)\n",
    "        out_post.append(post_im)\n",
    "    return out_anno, out_pre, out_post\n",
    "\n",
    "\n",
    "def geo_coords_to_image_coords(image_geotran, in_wkt):\n",
    "    \"\"\"translates WKT geometry in geographic coordinates (latitude, longitude) \n",
    "    to WKT geometry in image coordinates (col, row)\"\"\"\n",
    "    xmin = image_geotran[0]\n",
    "    xres = image_geotran[1]\n",
    "    ymax = image_geotran[3]\n",
    "    yres = image_geotran[5]\n",
    "    \n",
    "    shapely_poly = shapely.wkt.loads(in_wkt)\n",
    "    if shapely_poly.geom_type == 'MultiPolygon': # multipolygon\n",
    "        x, y = [], []\n",
    "        count = 0\n",
    "        for polygon in shapely_poly:\n",
    "            #print(count)\n",
    "            count+=1\n",
    "            x1,y1 = polygon.exterior.coords.xy\n",
    "            x.extend(x1)\n",
    "            y.extend(y1)\n",
    "    else: # polygon\n",
    "        x, y = shapely_poly.exterior.coords.xy\n",
    "    \n",
    "    outcoords = [] # [(x. y),(x, y), ...]\n",
    "    for coord in range(len(x)):\\\n",
    "        outcoords.append(((x[coord]-xmin)/xres, (y[coord]-ymax)/yres))\n",
    "    out_wkt = Polygon(outcoords).wkt\n",
    "    return out_wkt\n",
    "\n",
    "def get_building_features(geojson_dict):\n",
    "    out_features = []\n",
    "    for i in geojson_dict[\"features\"]:\n",
    "        if \"building\" in i[\"properties\"]:\n",
    "            if i[\"properties\"][\"building\"] != None:\n",
    "                out_features.append(i)\n",
    "    return out_features\n",
    "\n",
    "def bldg_geojson_to_wkt(geojsons, images, output_csv_path):\n",
    "    wkt_list_tot = []\n",
    "    for i in range(len(images)):\n",
    "        geojson_path = geojsons[i]\n",
    "        im_path = images[i]\n",
    "        ds = gdal.Open(im_path)\n",
    "        geotran = ds.GetGeoTransform()\n",
    "        raster_srs = osr.SpatialReference()\n",
    "        raster_srs.ImportFromWkt(ds.GetProjectionRef())\n",
    "        raster_srs_epsg = int(raster_srs.GetAttrValue(\"AUTHORITY\", 1))\n",
    "        assert(raster_srs_epsg == 4326)\n",
    "        ds = None\n",
    "        \n",
    "        im_id = os.path.basename(im_path).split(\".\")[0]\n",
    "        \n",
    "        f = open(geojson_path)\n",
    "        data = json.load(f)\n",
    "        f.close()\n",
    "        \n",
    "        feats = get_building_features(data)\n",
    "        if len(feats) == 0:\n",
    "            wkt_list_tot.append([im_id, \"Building\", \"POLYGON EMPTY\", \"Null\", \"Null\", \"Null\"])\n",
    "        else:\n",
    "            for b in feats:\n",
    "                if \"flooded\" in b[\"properties\"]:\n",
    "                    flood = b[\"properties\"][\"flooded\"]\n",
    "                    fout = True\n",
    "                    if flood in [None, \"no\", 0, \"0\", \"No\", \"false\", False, \"False\"]:\n",
    "                        fout = False\n",
    "                    else:\n",
    "                        pass\n",
    "                        #print(flood)\n",
    "                        #print(     b[\"properties\"])\n",
    "                else:\n",
    "                    fout = False\n",
    "                #print(b[\"geometry\"])\n",
    "                wkt = geo_coords_to_image_coords(geotran, shape(b[\"geometry\"]).wkt)\n",
    "                wkt_list_tot.append([im_id, \"Building\", wkt, fout, \"Null\", \"Null\"])\n",
    "            \n",
    "    \n",
    "    print(len(wkt_list_tot))\n",
    "    cols = ['ImageId','Object','Wkt_Pix','Flooded', 'length_m', 'travel_time_s'] \n",
    "    df = pd.DataFrame(wkt_list_tot, columns=cols)\n",
    "    print(\"df:\", df)\n",
    "    \n",
    "    df.to_csv(output_csv_path, mode='a', index=False, header=False)\n",
    "    #df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ae997e",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"\" # path to directory holding the aoi_dirs\n",
    "aoi_dirs = [\"\"] # directory name of each AOI to process\n",
    "output_csv_path = \"\" # name of the output csv to write the data to.\n",
    "\n",
    "\n",
    "# gather the prepped and cleaned geojson labels\n",
    "geojsons = []\n",
    "pre_images = []\n",
    "post_images = []\n",
    "for i in aoi_dirs:\n",
    "    assert(os.path.exists(os.path.join(root_dir, i))), \"error: aoi doesn't exist\"\n",
    "    anno = glob.glob(os.path.join(root_dir, i, \"annotations/prepped_cleaned\", \"roads_speed*.geojson\"))\n",
    "    pre = glob.glob(os.path.join(root_dir, i, \"PRE-event\", \"*.tif\"))\n",
    "    post = glob.glob(os.path.join(root_dir, i, \"POST-event\", \"*.tif\"))\n",
    "    print(\"number of annotations: \", len(anno))\n",
    "    print(\"number of pre: \", len(pre))\n",
    "    print(\"number of post: \", len(post))\n",
    "    annot, preims, postims = match_im_label_road(anno, pre, post)\n",
    "    print(\"AFTER MATCH\")\n",
    "    print(\"number of annotations: \", len(annot))\n",
    "    print(\"number of pre: \", len(preims))\n",
    "    print(\"number of post: \", len(postims))\n",
    "all_records = []\n",
    "for i in range(len(annot)):\n",
    "    recs = get_records(annot[i], preims[i])\n",
    "    if len(recs) == 0:\n",
    "        all_records.append([os.path.basename(preims[i]).split(\".\")[0], \"Road\",\"LINESTRING EMPTY\", \"Null\", \"Null\", \"Null\"])\n",
    "    for r in recs:\n",
    "        all_records.append(r)\n",
    "\n",
    "df = pd.DataFrame(all_records, columns=['ImageId','Object','Wkt_Pix','Flooded', 'length_m', 'travel_time_s'])\n",
    "print(\"df:\", df)\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "\n",
    "# now do the same for buildings.\n",
    "geojsons = []\n",
    "pre_images = []\n",
    "post_images = []\n",
    "for i in aoi_dirs:\n",
    "    assert(os.path.exists(os.path.join(root_dir, i))), \"error: aoi doesn't exist\"\n",
    "\n",
    "    anno = glob.glob(os.path.join(root_dir, i, \"annotations\", \"*.geojson\"))\n",
    "    pre = glob.glob(os.path.join(root_dir, i, \"PRE-event\", \"*.tif\"))\n",
    "    post = glob.glob(os.path.join(root_dir, i, \"POST-event\", \"*.tif\"))\n",
    "\n",
    "    print(\"number of annotations: \", len(anno))\n",
    "    print(\"number of pre: \", len(pre))\n",
    "    print(\"number of post: \", len(post))\n",
    "\n",
    "    annot, preims, postims = match_im_label(anno, pre, post)\n",
    "    \n",
    "    print(\"AFTER MATCH\")\n",
    "    print(\"number of annotations: \", len(annot))\n",
    "    print(\"number of pre: \", len(preims))\n",
    "    print(\"number of post: \", len(postims))\n",
    "\n",
    "bldg_geojson_to_wkt(annot, preims, output_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c49cac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
